{
"total_score": 75,
"scores_by_criteria": {
"완성도": 17,
"구체성": 13,
"논리성": 16,
"차별성": 13,
"제출완성도": 10,
"문서형식": 6
},
"defect_tags": ["FORMAT_NONCOMPLIANCE", "NO_EVIDENCE_OR_CITATION", "VAGUE_CLAIMS"],
"proposed_tags": [],
"evidence_anchors": [
{
"location": "나. 현재 개발 단계(TRL 기준) 및 주요 기술 검증",
"issue": "TRL 수준을 서술(관련 환경 검증)로만 표현하고 TRL 번호(예: TRL 5/6)로 명시하지 않아 투자자 관점의 준비도 커뮤니케이션이 약함",
"quote": "현재 개발 단계는 TRL 프레임에서 “관련 환경에서의 검증”에 해당하는 위치로 정의하며"
},
{
"location": "KPI 체계 표",
"issue": "표가 마크다운 표 형식이 아니어서 문서형식 기준 미달(가독성/재사용성 저하)",
"quote": "KPI 항목(6~10개) 정의 측정 방법 내부 측정 요약(측정 창/표본 정의 포함) 증빙 산출물(로그/리포트/정책/명세) 현재 검증 상태(완료/부분/미착수) 남은 리스크/다음 조치"
},
{
"location": "가. 개발 이력/추진 경과",
"issue": "PoC 완료/가능 범위 확인 등 핵심 준비도 주장에 대해 최소한의 정량 결과(예: 재현성 %, 오탐률, 처리량) 또는 산출물 식별자(리포트 버전/날짜)가 없어 검증가능성이 약함",
"quote": "AI 모델 PoC를 먼저 완료하여 “탐지 후보 생성과 근거 제시”의 가능 범위를 확인했고"
},
{
"location": "다. 파일럿/테스트 결과 및 목표시장 반응",
"issue": "내부 테스터 기반 반응을 제시하나 표본 수, 모집 기준, 테스트 과제/기간 등 실험 설계 정보가 부족해 근거력이 약함",
"quote": "파일럿/테스트는 외부 도입이 아니라 내부 테스터 기반으로 진행했으며"
},
{
"location": "라. 현재까지 주요 성과 및 다음 단계",
"issue": "‘대안 유형 대비 결정적 우위’가 선언형으로 정리되어 있으나, 경쟁 대안 대비 측정 가능한 비교축(탐지 커버리지, MTTR, 재발감시, 단가 등)과 근거가 부족함",
"quote": "대안 유형 대비 결정적 우위는 다음 3가지로 고정한다."
}
],
"strengths": [
"준비도를 ‘정량 KPI 결과’가 아닌 ‘측정 설계+증빙 산출물+검증 상태’로 정의해 상용화 전 검증 체계를 문서화한 점이 투자자 실사(DD) 친화적임",
"오탐/프라이버시/운영 리스크를 KPI 항목과 절차(되돌림, 증거보존, 접근통제)로 연결해 운영 가능성(operational readiness)을 강조한 구성은 설득력이 있음",
"TRL 프레임과 Go/No-Go 게이트를 제시해 다음 단계 의사결정 기준을 ‘통과 조건’으로 고정한 점은 실행 계획의 선명도를 높임"
],
"weaknesses": [
{
"issue": "핵심 준비도(탐지 성능/재현성/오탐/처리량/지연시간)에 대한 최소 정량 근거가 부재하여 ‘검증 완료/부분’의 실질 의미가 약함",
"fix": "내부 테스트 기준선으로도 충분하므로 KPI별로 최소 1개 정량 지표(예: 후보 재현성 %, 오탐률/정탐률, 평균 탐지 지연, 중복 알림률, 수집 성공률)를 ‘측정 창/표본/산출물 버전’과 함께 제시"
},
{
"issue": "TRL 매핑이 서술형이며 TRL 번호/요건 대비 충족 여부가 명확하지 않음",
"fix": "‘현재 TRL X’로 번호를 명시하고, NASA 정의의 핵심 요건(환경/통합/검증 산출물)을 체크리스트 형태로 충족/미충족을 표시"
},
{
"issue": "내부 파일럿 반응이 정성 중심이며 실험 설계(표본 수, 선정 기준, 과제, 기간, 관찰 지표)가 부족",
"fix": "내부 테스터 N, 테스트 기간, 시나리오 수, 채널 커버리지, 수집/탐지 이벤트 수 등 최소 메타데이터를 추가하고, 상위 3개 이슈를 ‘발생 빈도’로 우선순위화"
},
{
"issue": "차별성이 ‘근거 제시/조치 상태 추적/프라이버시 설계’로 정리되나 경쟁 대안 대비 비교 가능한 성과축이 부족",
"fix": "대안 유형(수동 검색/단일 채널/조치 대행)별로 비교표를 만들고, 최소 3개 비교축(탐지 커버리지, 조치 MTTR, 재발 감시, 사용자 작업량)을 정의해 MVP 단계라도 내부 수치로 비교"
},
{
"issue": "KPI 표가 마크다운 표가 아니어서 제출 형식 요건 및 가독성 저하",
"fix": "KPI 표를 파이프(|) 기반 마크다운 표로 재작성하고, 각 행의 ‘현재 검증 상태’ 기준(완료/부분/미착수 판단 규칙)을 각주로 명시"
}
],
"format_issues": [
{
"issue": "KPI 표가 마크다운 표 형식이 아님(열 구분자 | 및 헤더 구분선 누락)",
"fix": "마크다운 표로 변환(헤더 행 + --- 구분선 + 각 KPI 행)하고, 긴 텍스트는 줄바꿈(<br>) 또는 요약 키워드로 정리"
}
],
"priority_fix": "KPI 표를 마크다운 표로 재작성하면서, 각 KPI에 최소 1개의 정량 기준선(내부 테스트 기준)과 표본/기간/산출물 버전 정보를 함께 넣어 ‘부분/완료’의 의미를 객관화할 것",
"prompt_patch_suggestions": [
"‘TRL 관련 환경 검증’ 서술만 금지: 반드시 ‘현재 TRL 번호(예: TRL 5/6)’와 NASA 정의 요건 체크리스트(충족/미충족)를 포함하라.",
"KPI 표는 반드시 마크다운 표(|)로 작성하고, KPI는 8~10개로 고정하며 각 KPI에 ‘최소 1개 정량 기준선(내부 테스트 수치 가능)’을 포함하라.",
"파일럿/테스트 결과에는 ‘테스터 수(N), 기간, 시나리오 수, 관찰 지표 3개, 발견 이슈 Top3(빈도/심각도)’를 필수로 포함하라.",
"‘완료/부분/미착수’ 판정 규칙을 문서 내에서 명시하고, 각 항목별 산출물에는 ‘문서/리포트 버전 또는 생성일’ 식별자를 포함하라.",
"차별성은 대안 유형별 비교표로 제시하고, 비교축(커버리지/MTTR/사용자 작업량/재발감시)을 정의한 뒤 최소 내부 수치 또는 시뮬레이션 결과로 뒷받침하라."
]
}
